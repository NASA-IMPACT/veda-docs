---
title: "Dataset Ingestion"
subtitle: "Guide to ingesting and publishing data to the VEDA data store & STAC API"
---

VEDA uses a centralized [Spatio-Temporal Asset Catalog (STAC)](https://stacspec.org/) for data dissemination and prefers to hosts datasets in cloud-object storage ([AWS S3](https://aws.amazon.com/s3/) in the region `us-west-2`)
in the cloud-optimized file formats [Cloud-Optimized GeoTIFF (COG)](https://www.cogeo.org/) and [Zarr](https://zarr.dev/), which enables viewing and efficient access in the cloud directly
from the original datafiles without copies or multiple versions.


## Steps for ingesting a dataset

For dataset ingestion, generally four steps are required. Depending on the capacity of the dataset provider, some of the steps can be completed by the VEDA team on request.

Complete as many steps of the process as you have capacity or authorization to. Please see the guides below on

0. Open a dedicated [pull request in the veda-data-pipelines repository](https://github.com/NASA-IMPACT/veda-data-pipelines/issues/new?assignees=&labels=dataset&template=add-new-dataset-simple.md&title=Add+%3Cdataset+title%3E)
1. Transform datasets to conform with cloud-optimized file formats - see [file preparation](./file-preparation.qmd)
2. Upload files to storage (may be skipped, if data is cloud-optimized and in `us-west-2`)
3. Create compliant metadata records for our STAC - see [example](./notebooks/new-collection.html) and [conventions](./stac-collection-conventions.qmd) for STAC collections and [example](./notebooks/new-item.html)
and [conventions](./stac-item-conventions.qmd) for STAC items.
4. Load those records into the VEDA STAC - see [catalog ingestion](./catalog-ingestion.qmd)